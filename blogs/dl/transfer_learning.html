<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title> 迁移学习 </title>

    <!-- Bootstrap core CSS -->
    <link href="../../vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="../../css/blog-home.css" rel="stylesheet">

  </head>

  <body>

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
      <div class="container">
        <a class="navbar-brand" href="../../index.html">Yifei's homepage</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item">
              <a class="nav-link" href="../../index.html">Home</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="../about/index.html">About</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="../cv/index.html">CV</a>
            </li>
            <li class="nav-item active">
              <a class="nav-link" href="../index.html">Blogs</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <!-- Page Content -->
    <div class="container">

      <div class="row">

        <!-- Blog Entries Column -->
        <div class="col-md-12">

          <h1 class="my-4"> -- </h1>

          <!-- Blog Post -->
          <div class="card mb-4">
            <div class="card-body">
              <h2 class="card-title"> 迁移学习 </h2>
              <p class ='card-text'>
<br><br>
在搭建自己的深度神经网络的时候，我们完全可以借鉴别人已有的成功经验，比如 ALEX NET，VGG NET， RESNET，等等。
<br>
这种方法就叫做 迁移学习 <strong> transfer learning </strong> <br><br>
什么时候，以及我们应该如何迁移？<br><br><br>

对于不同的任务我们要采用不同的策略。<br>
如果你有一个来自很大数据集（百万级以上）的已经训练好的模型，当你面对自己的训练集来完成你的目的时，
<br>
<img src="./transfer_learning/02-guide-how-transfer-learning-v3-02.png" height = '300'>
<br><br><br>

1. 你的训练集很大，训练任务很相似。<br>
==> 复制已有的模型结构，以已经训练好的模型为开始状态，在你的训练集上继续训练（fine tune）
<br>
<img src="./transfer_learning/02-guide-how-transfer-learning-v3-08.png" height = '300'>
<br><br><br>

2. 你的训练集很大，训练任务不相似。<br>
==> 复制已有的模型结构，重新开始训练（或者 fine tune 也可以）
<br>
<img src="./transfer_learning/02-guide-how-transfer-learning-v3-10.png" height = '300'>
<br><br><br>

3. 你的训练集很小，任务很相似。<br>
==> 复制已有的结构模型，只在最后一层改为你需要的输出，冻结前面所有的模型参数，只训练最后输出层的参数
<br>
<img src="./transfer_learning/02-guide-how-transfer-learning-v3-04.png" height = '300'>
<br><br><br>

4. 你的训练集很小，训练任务不相似。<br>
==> 无他，重新设计你的模型并开始训练（迁移学习也无解）
<br>
<img src="./transfer_learning/02-guide-how-transfer-learning-v3-06.png" height = '300'>
<br><br><br>

<hr>
总结起来，就是如下：<br>
<img src="./transfer_learning/02-guide-how-transfer-learning.png" height = '300'>
<br><br><br>


<hr><hr>
既然采用了迁移学习，那么常用的两种方法就是 feature extraction 和 fine-tuning
<br><br>
前者在于，我们改变已有 model 的最后输出层（或者几层），同时对前面层的参数固定不变。<br>
后者在于，前面层的参数在训练的时候也是会改变的。<br>

换种理解，feature extraction 就是我们让样本现通过已有的模型的前面，得到在 high level 的 feature，
再对 high level 的 feature 进行训练。<br><br>

<br><br><br>

DEMO

<br><br>
这是一个利用AlexNet 来进行交通标志识别的模型 <br>
代码可以在下面的地址访问到：<br>
<a href="https://github.com/udacity/CarND-Alexnet-Feature-Extraction"> https://github.com/udacity/CarND-Alexnet-Feature-Extraction</a>

<br><br>
AlexNet 的相关论文可以在一下地址访问到：
<a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf"> AlexNet </a>

<br><br>

这里是一份 AlexNet 的 tensorflow 代码实现 <br>
<a href="http://www.cs.toronto.edu/~guerzhoy/tf_alexnet/"> tensorflow AlexNet </a>

训练集还是来自于
<a href="http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset"> German Traffic Sign Recognition Benchmark dataset</a>
这里有一个已经经过预处理的训练集：
<a href="https://d17h27t6h515a5.cloudfront.net/topher/2016/October/580a829f_train/train.p">train data set </a>

<br><br>

一个已经训练好的 AlexNet 模型，用 npy 文件格式保存的<br>
<a href="http://video.udacity-data.com.s3.amazonaws.com/topher/2016/October/580d880c_bvlc-alexnet/bvlc-alexnet.npy"> Bvlc Alexnet Weights </a>

<br><br>
我们来解读一下代码，看看这个 transfere learning 到底怎么做。

<br><br>
1. AlexNet <br><br>

首先我们要复现这个 AlexNet 的结构，<br><br>

<pre>
import numpy as np
import tensorflow as tf

net_data = np.load("bvlc-alexnet.npy", encoding="latin1").item()


def conv(input, kernel, biases, k_h, k_w, c_o, s_h, s_w,  padding="VALID", group=1):
    '''
    From https://github.com/ethereon/caffe-tensorflow
    '''
    c_i = input.get_shape()[-1]
    assert c_i % group == 0
    assert c_o % group == 0
    convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)

    if tf.__version__ < "1.0.0":
        if group == 1:
            conv = convolve(input, kernel)
        else:
            input_groups = tf.split(3, group, input)
            kernel_groups = tf.split(3, group, kernel)
            output_groups = [convolve(i, k) for i, k in zip(input_groups, kernel_groups)]
            conv = tf.concat(3, output_groups)
    else:
        if group == 1:
            conv = convolve(input, kernel)
        else:
            input_groups = tf.split(input, group, 3)
            kernel_groups = tf.split(kernel, group, 3)
            output_groups = [convolve(i, k) for i, k in zip(input_groups, kernel_groups)]
            conv = tf.concat(output_groups, 3)
    return tf.reshape(tf.nn.bias_add(conv, biases), [-1] + conv.get_shape().as_list()[1:])


def AlexNet(features, feature_extract=False):
    """
    Builds an AlexNet model, loads pretrained weights
    """
    # conv1
    # conv(11, 11, 96, 4, 4, padding='VALID', name='conv1')
    k_h = 11
    k_w = 11
    c_o = 96
    s_h = 4
    s_w = 4
    conv1W = tf.Variable(net_data["conv1"][0])
    conv1b = tf.Variable(net_data["conv1"][1])
    conv1_in = conv(features, conv1W, conv1b, k_h, k_w, c_o, s_h, s_w, padding="SAME", group=1)
    conv1 = tf.nn.relu(conv1_in)

    # lrn1
    # lrn(2, 2e-05, 0.75, name='norm1')
    radius = 2
    alpha = 2e-05
    beta = 0.75
    bias = 1.0
    lrn1 = tf.nn.local_response_normalization(conv1, depth_radius=radius, alpha=alpha, beta=beta, bias=bias)

    # maxpool1
    # max_pool(3, 3, 2, 2, padding='VALID', name='pool1')
    k_h = 3
    k_w = 3
    s_h = 2
    s_w = 2
    padding = 'VALID'
    maxpool1 = tf.nn.max_pool(lrn1, ksize=[1, k_h, k_w, 1], strides=[1, s_h, s_w, 1], padding=padding)

    # conv2
    # conv(5, 5, 256, 1, 1, group=2, name='conv2')
    k_h = 5
    k_w = 5
    c_o = 256
    s_h = 1
    s_w = 1
    group = 2
    conv2W = tf.Variable(net_data["conv2"][0])
    conv2b = tf.Variable(net_data["conv2"][1])
    conv2_in = conv(maxpool1, conv2W, conv2b, k_h, k_w, c_o, s_h, s_w, padding="SAME", group=group)
    conv2 = tf.nn.relu(conv2_in)

    # lrn2
    # lrn(2, 2e-05, 0.75, name='norm2')
    radius = 2
    alpha = 2e-05
    beta = 0.75
    bias = 1.0
    lrn2 = tf.nn.local_response_normalization(conv2, depth_radius=radius, alpha=alpha, beta=beta, bias=bias)

    # maxpool2
    # max_pool(3, 3, 2, 2, padding='VALID', name='pool2')
    k_h = 3
    k_w = 3
    s_h = 2
    s_w = 2
    padding = 'VALID'
    maxpool2 = tf.nn.max_pool(lrn2, ksize=[1, k_h, k_w, 1], strides=[1, s_h, s_w, 1], padding=padding)

    # conv3
    # conv(3, 3, 384, 1, 1, name='conv3')
    k_h = 3
    k_w = 3
    c_o = 384
    s_h = 1
    s_w = 1
    group = 1
    conv3W = tf.Variable(net_data["conv3"][0])
    conv3b = tf.Variable(net_data["conv3"][1])
    conv3_in = conv(maxpool2, conv3W, conv3b, k_h, k_w, c_o, s_h, s_w, padding="SAME", group=group)
    conv3 = tf.nn.relu(conv3_in)

    # conv4
    # conv(3, 3, 384, 1, 1, group=2, name='conv4')
    k_h = 3
    k_w = 3
    c_o = 384
    s_h = 1
    s_w = 1
    group = 2
    conv4W = tf.Variable(net_data["conv4"][0])
    conv4b = tf.Variable(net_data["conv4"][1])
    conv4_in = conv(conv3, conv4W, conv4b, k_h, k_w, c_o, s_h, s_w, padding="SAME", group=group)
    conv4 = tf.nn.relu(conv4_in)

    # conv5
    # conv(3, 3, 256, 1, 1, group=2, name='conv5')
    k_h = 3
    k_w = 3
    c_o = 256
    s_h = 1
    s_w = 1
    group = 2
    conv5W = tf.Variable(net_data["conv5"][0])
    conv5b = tf.Variable(net_data["conv5"][1])
    conv5_in = conv(conv4, conv5W, conv5b, k_h, k_w, c_o, s_h, s_w, padding="SAME", group=group)
    conv5 = tf.nn.relu(conv5_in)

    # maxpool5
    # max_pool(3, 3, 2, 2, padding='VALID', name='pool5')
    k_h = 3
    k_w = 3
    s_h = 2
    s_w = 2
    padding = 'VALID'
    maxpool5 = tf.nn.max_pool(conv5, ksize=[1, k_h, k_w, 1], strides=[1, s_h, s_w, 1], padding=padding)

    # fc6, 4096
    fc6W = tf.Variable(net_data["fc6"][0])
    fc6b = tf.Variable(net_data["fc6"][1])
    flat5 = tf.reshape(maxpool5, [-1, int(np.prod(maxpool5.get_shape()[1:]))])
    fc6 = tf.nn.relu(tf.matmul(flat5, fc6W) + fc6b)

    # fc7, 4096
    fc7W = tf.Variable(net_data["fc7"][0])
    fc7b = tf.Variable(net_data["fc7"][1])
    fc7 = tf.nn.relu(tf.matmul(fc6, fc7W) + fc7b)

    if feature_extract:
        return fc7

    # fc8, 1000
    fc8W = tf.Variable(net_data["fc8"][0])
    fc8b = tf.Variable(net_data["fc8"][1])

    logits = tf.matmul(fc7, fc8W) + fc8b
    probabilities = tf.nn.softmax(logits)

    return probabilities
</pre>

feature extraction <br>
如何利用 AlexNet 提取特征？

<br><br>

<pre>
import time
import tensorflow as tf
import numpy as np
import pandas as pd
from scipy.misc import imread
from alexnet import AlexNet

sign_names = pd.read_csv('signnames.csv')
nb_classes = 43

x = tf.placeholder(tf.float32, (None, 32, 32, 3))
resized = tf.image.resize_images(x, (227, 227))

# Returns the second final layer of the AlexNet model,
# this allows us to redo the last layer specifically for 
# traffic signs model.
fc7 = AlexNet(resized, feature_extract=True)
shape = (fc7.get_shape().as_list()[-1], nb_classes)
fc8W = tf.Variable(tf.truncated_normal(shape, stddev=1e-2))
fc8b = tf.Variable(tf.zeros(nb_classes))
logits = tf.nn.xw_plus_b(fc7, fc8W, fc8b)
probs = tf.nn.softmax(logits)

init = tf.initialize_all_variables()
sess = tf.Session()
sess.run(init)

# Read Images
im1 = imread("construction.jpg").astype(np.float32)
im1 = im1 - np.mean(im1)

im2 = imread("stop.jpg").astype(np.float32)
im2 = im2 - np.mean(im2)

# Run Inference
t = time.time()
output = sess.run(probs, feed_dict={x: [im1, im2]})

# Print Output
for input_im_ind in range(output.shape[0]):
    inds = np.argsort(output)[input_im_ind, :]
    print("Image", input_im_ind)
    for i in range(5):
        print("%s: %.3f" % (sign_names.ix[inds[-1 - i]][1], output[input_im_ind, inds[-1 - i]]))
    print()

print("Time: %.3f seconds" % (time.time() - t))

</pre>













              </p>
              
            </div>
            <div class="card-footer text-muted">
              Posted on 2018-07-07 by Yifei
              <!-- <a href="#">Start Bootstrap</a> -->
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Footer -->
    <footer class="py-5 bg-dark">
      <div class="container">
        <p class="m-0 text-center text-white">Yifei Huang 2018</p>
      </div>
      <!-- /.container -->
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script src="startbootstrap-blog-post-gh-pages/vendor/jquery/jquery.min.js"></script>
    <script src="startbootstrap-blog-post-gh-pages/vendor/popper/popper.min.js"></script>
    <script src="startbootstrap-blog-post-gh-pages/vendor/bootstrap/js/bootstrap.min.js"></script>

  </body>

</html>
